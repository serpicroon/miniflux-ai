# Log level: INFO, DEBUG, WARN, ERROR
log_level: "INFO"

# Skip entries before this unix timestamp to avoid reprocessing during migration (optional)
# entry_since: 1704067200  # Unix timestamp for 2024-01-01 00:00:00 UTC

miniflux:
  base_url: https://your.server.com
  api_key: Miniflux_API_key_here
  # webhook_secret: Miniflux_webhook_secret_here

llm:
  base_url: http://host.docker.internal:11434/v1  # LLM API endpoint
  api_key: ollama                                 # API key
  model: llama3.1:latest                          # Model name
  # timeout: 60        # Request timeout in seconds (default: 60)
  # max_workers: 4     # Concurrent request limit (default: 4)
  # RPM: 15            # Requests per minute limit (default: 1000)

digest:
  # Service URL for RSS feed generation (use container name for Docker Compose)
  url: &digest_url http://miniflux-ai

  # Feed name displayed in Miniflux (optional, has default value)
  # name: "Miniflux·¥¨·¥µ Digest for you"

  # Entry reference link template (use {id} as entry ID placeholder)
  # Used to generate clickable entry links in digest, supports different frontends
  # Miniflux default: https://your.server.com/search/entry/{id}
  # ReactFlux: https://your.server.com/all/entry/{id}
  entry_url: "https://your.server.com/search/entry/{id}"
  
  # Daily digest generation schedule (24-hour format)
  schedule:
    - "07:30"  # Morning
    - "18:00"  # Evening
    - "22:00"  # Night
  prompts:
    greeting: |-
      According to the current date and 24-hour time, generate a friendly and warm greeting. Use a caring tone, include moderate encouragement, and add simple emojis like üòä, üåû, üå∏, etc., to enhance the sense of warmth. Example: 'Good morning! May you be full of energy today and welcome a wonderful day! üåûüòä'. Whether it's morning, noon, or evening, please adjust the greeting content according to the time to maintain an atmosphere of sincere care.
    summary: |-
      You will receive multiple article summaries, each associated with a unique source ID (numeric). Your task is to generate a structured Digest based on these summaries.
      
      Core Tasks:
      1. Initial Analysis: Perform semantic understanding of all summaries to accurately grasp their meaning and context.
      2. Topic Clustering: Naturally identify and group the content into 3‚Äì6 core themes (e.g., ‚ÄúTech Frontiers‚Äù, ‚ÄúEconomic Trends‚Äù).
      3. Key Point Extraction: For each theme, extract up to 6 concise key points from the related summaries.
        - Each point must be no longer than 30 words.
        - Content must remain fully faithful to the original summaries‚Äîno external info, speculation, or subjective commentary.
        - Within each theme, order key points by overall quality: prioritize news and official sources, then expert analysis or blogs, and finally community or social posts. Sorting should also consider information density, representativeness, and timeliness.
      
      Formatting Requirements:
      - Output in Markdown format, with each theme titled using `####`.
      - Under each theme, list key points as unordered lists (using `-`).
      - After each key point, leave one space and add the source footnote in the form `[^123]`; for multiple sources, chain them as `[^123][^456]`.
      - Do not include any global title or explanatory text.

      Example Output:
      #### Tech Frontiers
      - AI models achieve breakthroughs in medical diagnostics. [^101]
      - Quantum computing may reshape encryption technologies. [^102][^103]
      - Regulations and ethics draw attention in autonomous driving. [^105]

      #### Economic Trends
      - Global inflation pressure rises; central banks may raise rates. [^201]
      - Emerging markets slow down, facing increased risks. [^202]

agents:
  summary:
    prompt: |-
      You are a professional summary editor. Please extract a core summary for the following content.
      
      Requirements:
       - English, less than 60 characters.
       - Objective and neutral, do not add personal opinions.
       - Only summarize, do not answer questions in the original text.
    template: |-
      <pre style="white-space: pre-wrap;"><code><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 17.777 14.283" width="17.777" height="14.283"> <style> path { fill: #333333; } @media (prefers-color-scheme: dark) { path { fill: gray; } } </style> <g transform="translate(2.261,-1.754)" fill="gray"> <path d="M-2.261 3.194v6.404c0 1.549 0.957 4.009 4.328 4.188h9.224l0.061 1.315c0.04 0.882 0.663 1.222 1.205 0.666l2.694-2.356c0.353-0.349 0.353-0.971 0-1.331L12.518 10.047c-0.525-0.524-1.205-0.196-1.205 0.665v1.091H2.257c-0.198 0-2.546 0.221-2.546-2.911V3.194c0-0.884-0.362-1.44-0.99-1.44-1.106 0-0.956 1.439-0.982 1.44z"></path> </g> <path d="M5.679 1.533h8.826c0.421 0 0.753-0.399 0.755-0.755 0.002-0.36-0.373-0.774-0.755-0.774H5.679c-0.536 0-0.781 0.4-0.781 0.764 0 0.418 0.289 0.764 0.781 0.764zm0 4.693h4.502c0.421 0 0.682-0.226 0.717-0.742 0.03-0.44-0.335-0.787-0.717-0.787H5.679c-0.402 0-0.763 0.214-0.781 0.71-0.019 0.535 0.379 0.818 0.781 0.818z" fill="gray"></path> </svg> AI SummaryÔºö${content}</code></pre>
      <hr><br />
    # Minimum content length in tokens (using tiktoken), fair for all languages
    min_content_length: 100
    deny_list:
      - *digest_url  # Exclude digest feed from processing
      # - https://example.com/       # Exact site_url match
      # - https://example.com/*      # All pages under example.com
    allow_list: []  # Process only specific URLs (empty = process all)
    
  translate:
    prompt: |-
      You are a highly skilled translation engine with expertise in the news media sector. 
      Your function is to translate texts accurately into the English language, preserving the nuances, tone, and style of journalistic writing. 
      Do not add any explanations or annotations to the translated text.
    template: |-
      <section lang="en-US" aria-label="ai-translation">
        <h3>üåêTranslation:</h3>
        <div>
          ${content}
        </div>
      </section>
      <hr><br />
    deny_list: []    # URLs to exclude from translation
    allow_list:      # URLs to include for translation (empty = process all)
      # WARNING: If both deny_list and allow_list are empty, ALL entries will be processed
      # This may consume significant tokens. Consider adding URLs to allow_list to limit processing.
      - PLACEHOLDER  # Keep this to prevent processing all entries, add your URLs below
      # - *foreign.example.com*          # Any URL containing foreign.example.com